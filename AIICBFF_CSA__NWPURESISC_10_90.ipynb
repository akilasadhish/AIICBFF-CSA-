{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akilasadhish/AIICBFF-CSA-/blob/main/AIICBFF_CSA__NWPURESISC_10_90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcyILCuY3ls0"
      },
      "outputs": [],
      "source": [
        "from contextlib import suppress\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "from zipfile import ZipFile\n",
        "from skimage.io import imread, imsave\n",
        "import tensorflow as tf\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UqhFIseunx5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wK-Lk5yOgGi"
      },
      "outputs": [],
      "source": [
        "!pip install pyunpack\n",
        "!pip install patool\n",
        "from pyunpack import Archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq_9sXN1OkE7"
      },
      "outputs": [],
      "source": [
        "import patoolib\n",
        "\n",
        "if not os.path.isdir(source_dir):\n",
        "  patoolib.extract_archive(\"/content/drive/MyDrive/NWPU-RESISC45.rar\", outdir=\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QNm6i1xOiFx"
      },
      "outputs": [],
      "source": [
        "source_dir = os.path.join('data', 'NWPU-RESISC45')\n",
        "with suppress(FileExistsError):\n",
        "    os.mkdir('data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KskZFZt3zun"
      },
      "outputs": [],
      "source": [
        "class_names = os.listdir(source_dir)   \n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oLWwLpy32wH"
      },
      "outputs": [],
      "source": [
        "flow_base2 = os.path.join('data', 'result')\n",
        "if not os.path.isdir(flow_base2):\n",
        "  # Make new directories\n",
        "  os.mkdir(flow_base2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNrLFMuI36JJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(list())\n",
        "df.to_csv('/content/data/result/XXX.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqjxuVOM38aP"
      },
      "outputs": [],
      "source": [
        "!pip install -q split-folders\n",
        "import splitfolders\n",
        "splitfolders.ratio('/content/data/NWPU-RESISC45', output='/content/data/flow', seed=1337,  ratio=(0.2, 0.6, 0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h05Hy9qC4Mkn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Lambda, Dense, Reshape\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Add, Concatenate, multiply, GlobalMaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoc1FHst4O4Y"
      },
      "outputs": [],
      "source": [
        "def cbam_block(cbam_feature, ratio=16):\n",
        "\tcbam_feature = channel_attention(cbam_feature, ratio)\n",
        "\tcbam_feature = spatial_attention(cbam_feature)\n",
        "\treturn cbam_feature\n",
        "\n",
        "def channel_attention(input_feature, ratio=16):\n",
        "\t\n",
        "\tchannel_axis = 1 if tf.keras.backend.image_data_format() == \"channels_first\" else -1\n",
        "\tchannel = input_feature.shape[channel_axis]\n",
        "\t\n",
        "\tshared_layer_one = Dense(channel//ratio,\n",
        "\t\t\t\t\t\t\t activation='relu',\n",
        "\t\t\t\t\t\t\t kernel_initializer='he_normal',\n",
        "\t\t\t\t\t\t\t use_bias=True,\n",
        "\t\t\t\t\t\t\t bias_initializer='zeros')\n",
        "\tshared_layer_two = Dense(channel,\n",
        "\t\t\t\t\t\t\t kernel_initializer='he_normal',\n",
        "\t\t\t\t\t\t\t use_bias=True,\n",
        "\t\t\t\t\t\t\t bias_initializer='zeros')\n",
        "\t\n",
        "\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n",
        "\tavg_pool = Keras.Reshape((1,1,channel))(avg_pool)\n",
        "\tassert avg_pool.shape[1:] == (1,1,channel)\n",
        "\tavg_pool = shared_layer_one(avg_pool)\n",
        "\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n",
        "\tavg_pool = shared_layer_two(avg_pool)\n",
        "\tassert avg_pool.shape[1:] == (1,1,channel)\n",
        "\t\n",
        "\tmax_pool = GlobalMaxPooling2D()(input_feature)\n",
        "\tmax_pool = Keras.Reshape((1,1,channel))(max_pool)\n",
        "\tassert max_pool.shape[1:] == (1,1,channel)\n",
        "\tmax_pool = shared_layer_one(max_pool)\n",
        "\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n",
        "\tmax_pool = shared_layer_two(max_pool)\n",
        "\tassert max_pool.shape[1:] == (1,1,channel)\n",
        "\t\n",
        "\tcbam_feature = Add()([avg_pool,max_pool])\n",
        "\tcbam_feature = Activation('sigmoid')(cbam_feature)\n",
        "\t\n",
        "\tif tf.keras.backend.image_data_format() == \"channels_first\":\n",
        "\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
        "\t\n",
        "\treturn multiply([input_feature, cbam_feature])\n",
        "\n",
        "def spatial_attention(input_feature):\n",
        "\tkernel_size = 7\n",
        "\t\n",
        "\tif tf.keras.backend.image_data_format() == \"channels_first\":\n",
        "\t\tchannel = input_feature._keras_shape[1]\n",
        "\t\tcbam_feature = Permute((2,3,1))(input_feature)\n",
        "\telse:\n",
        "\t\tchannel = input_feature.shape[-1]\n",
        "\t\tcbam_feature = input_feature\n",
        "\t\n",
        "\tavg_pool = Lambda(lambda x: tf.keras.backend.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
        "\tassert avg_pool.shape[-1] == 1\n",
        "\tmax_pool = Lambda(lambda x: tf.keras.backend.max(x, axis=3, keepdims=True))(cbam_feature)\n",
        "\tassert max_pool.shape[-1] == 1\n",
        "\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n",
        "\tassert concat.shape[-1] == 2\n",
        "\tcbam_feature = Conv2D(filters = 1,\n",
        "\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\tstrides=1,\n",
        "\t\t\t\t\tpadding='same',\n",
        "\t\t\t\t\tactivation='sigmoid',\n",
        "\t\t\t\t\tkernel_initializer='he_normal',\n",
        "\t\t\t\t\tuse_bias=False)(concat)\t\n",
        "\tassert cbam_feature.shape[-1] == 1\n",
        "\t\n",
        "\tif tf.keras.backend.image_data_format() == \"channels_first\":\n",
        "\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
        "\t\t\n",
        "\treturn multiply([input_feature, cbam_feature])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H16l_soP_1T"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization, Reshape, Lambda\n",
        "from tensorflow.keras.backend import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSDWO4YMBaoP"
      },
      "outputs": [],
      "source": [
        "def Resnet50_model1(input_shape, num_classes=45):\n",
        "  \n",
        "  model = ResNet50(include_top=False, input_shape=input_shape, pooling='avg', weights= 'imagenet')\n",
        "  for layer in model.layers[0:-95]:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "  model1 = model.layers[-2].output\n",
        "  model1 = channel_attention(model1,16)\n",
        "  model1 = GlobalAveragePooling2D()(model1)\n",
        "  model1 = Dense(24, activation = \"relu\")(model1)\n",
        "  model1 = BatchNormalization()(model1)\n",
        "  print(model1.shape)\n",
        "  \n",
        "  model2 = model.layers[-12].output\n",
        "  model2 = channel_attention(model2,16)\n",
        "  model2 = GlobalAveragePooling2D()(model2)\n",
        "  model2 = Dense(24, activation = \"relu\")(model2)\n",
        "  model2 = BatchNormalization()(model2)\n",
        "  print(model2.shape)\n",
        "  \n",
        "  model3 = model.layers[-22].output\n",
        "  model3 = cbam_block(model3,16)\n",
        "  model3 = GlobalAveragePooling2D()(model3)\n",
        "  model3 = Dense(24, activation = \"relu\")(model3)\n",
        "  model3 = BatchNormalization()(model3)\n",
        "  print(model3.shape)\n",
        "  \n",
        "\n",
        "  model4 = model.layers[-34].output\n",
        "  model4 = cbam_block(model4,16)\n",
        "  model4 = GlobalAveragePooling2D()(model4)\n",
        "  model4 = Dense(24, activation = \"relu\")(model4)\n",
        "  model4 = BatchNormalization()(model4)\n",
        "  print(model4.shape)\n",
        "  \n",
        "  model5 = model.layers[-96].output\n",
        "  model5 = cbam_block(model5,16)\n",
        "  model5 = GlobalAveragePooling2D()(model5)\n",
        " \n",
        "\n",
        "  model5 = Dense(24, activation = \"relu\")(model5)\n",
        "  model5 = BatchNormalization()(model5)\n",
        "  print(model5.shape)\n",
        "\n",
        "  x = Concatenate()([model1, model2, model3, model4, model5])\n",
        "  \n",
        "  predictions = Dense(45, activation=\"softmax\")(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs = model.input, outputs = predictions)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUeUakLq42Gg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
        "from tensorflow.keras.optimizers import Adam,Nadam, SGD\n",
        "\n",
        "trainset_dir = '/content/data/flow/train'\n",
        "valset_dir = '/content/data/flow/test/'\n",
        "testset_dir = '/content/data/flow/val/'\n",
        "\n",
        "num_classes = 45\n",
        "learning_rate = 1e-2\n",
        "momentum = 0.9\n",
        "batch_size = 16\n",
        "input_shape = (224, 224, 3)\n",
        "train_datagen = ImageDataGenerator(dtype='float32', preprocessing_function=preprocess_input,\n",
        "        rotation_range = 60,\n",
        "        width_shift_range = 0.2,\n",
        "        height_shift_range = 0.2,\n",
        "        horizontal_flip = True,\n",
        "        vertical_flip = True,\n",
        "        fill_mode='nearest')\n",
        "val_datagen = ImageDataGenerator(dtype='float32', preprocessing_function=preprocess_input)\n",
        "test_datagen = ImageDataGenerator(dtype='float32', preprocessing_function=preprocess_input)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    trainset_dir,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    valset_dir,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical', shuffle = False)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    testset_dir,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical', shuffle= False)\n",
        "\n",
        "optim = SGD(learning_rate=learning_rate, momentum=momentum)\n",
        "# optim = RMSprop(lr=learning_rate)\n",
        "# optim = Adam(amsgrad=True)\n",
        "model = Resnet50_model1(input_shape, num_classes = 45 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51LuXL8O498_"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXlhbJkAGpjJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYhz74Ld5BsP"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXttAY8Yv4ZE"
      },
      "outputs": [],
      "source": [
        "loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.1)\n",
        "model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['acc'])\n",
        "csv_path = '/content/data/result/XXX.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_weights_path = '/content/drive/MyDrive/model_save/RSSC/10modelrssc.h5'\n",
        "#You can modify the path by yourself\n",
        "\n",
        "checkpoint = ModelCheckpoint(save_weights_path, monitor='val_acc', verbose=1, \n",
        "                             save_weights_only=True, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=32, verbose=1)\n",
        "# logging = TensorBoard(log_dir=log_dir, batch_size=batch_size)\n",
        "csvlogger = CSVLogger(csv_path, append=True)\n",
        "\n",
        "callbacks = [checkpoint, reduce_lr, csvlogger]\n",
        "\n",
        "num_epochs = 500\n",
        "\n",
        "model.fit(train_generator,\n",
        "          steps_per_epoch=len(train_generator),\n",
        "          epochs=num_epochs,\n",
        "          verbose=1, \n",
        "          callbacks=callbacks, \n",
        "          validation_data=test_generator, \n",
        "          validation_steps=len(test_generator),\n",
        "          workers=1)"
      ],
      "metadata": {
        "id": "IhYFb-CJhYVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc = model.evaluate(val_generator)\n",
        "print(\"Test Accuracy: {}%\".format(acc*100))"
      ],
      "metadata": {
        "id": "yIfDjNzIqiop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = model.evaluate_generator(val_generator, batch_size)\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(test_score[1] * 100))\n",
        "print(\"[INFO] Loss: \",test_score[0])"
      ],
      "metadata": {
        "id": "9-4Wjo0J-rx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "  plt.figure(figsize=(20,20))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=21)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  if normalize:\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    cm = np.around(cm, decimals=2)\n",
        "    cm[np.isnan(cm)] = 0.0\n",
        "    print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "      print('Confusion matrix, without normalization')\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "sF8Zj00ZNY2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the Target names\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools \n",
        "#shuffle=False\n",
        "target_names = []\n",
        "for key in train_generator.class_indices:\n",
        "    target_names.append(key)\n",
        "# print(target_names)\n",
        "#Confution Matrix\n",
        "Y_pred = model.predict_generator(val_generator)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "cm = confusion_matrix(val_generator.classes, y_pred)\n",
        "plot_confusion_matrix(cm, target_names, title='Confusion Matrix - NWPU-RESISC 10/90')\n"
      ],
      "metadata": {
        "id": "FyGsEpTdh8hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clsf_report = pd.DataFrame(classification_report(val_generator.classes, y_pred, target_names=target_names, output_dict=True)).transpose()\n",
        "print(clsf_report.to_csv('/content/data/result/clsf_report.csv', index= True))\n",
        "print(clsf_report)"
      ],
      "metadata": {
        "id": "gfKXQ0OMiCQi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}